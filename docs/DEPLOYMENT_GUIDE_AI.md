# üõ† Guide de D√©ploiement : Modules IA Agentique

Ce guide d√©taille les √©tapes n√©cessaires pour activer les fonctionnalit√©s d'IA bas√©es sur LangGraph en production.

## 1. Pr√©-requis d'Environnement

Ajouter les variables suivantes dans votre `.env` (local) et dans les variables d'environnement Vercel/Supabase :

```bash
# Requis pour les appels LLM r√©els
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxx
```

> **Note :** Le code actuel est configur√© avec un mode "Simulation" (Mock) par d√©faut pour √©viter de consommer des cr√©dits API pendant le d√©veloppement. Pour activer le vrai LLM, vous devez d√©commenter les sections `ChatOpenAI` dans les fichiers `.graph.ts` situ√©s dans `features/*/ai/`.

## 2. Migrations Base de Donn√©es

Trois migrations SQL doivent √™tre appliqu√©es pour stocker les r√©sultats des analyses IA.

Ex√©cutez les fichiers suivants via l'√©diteur SQL de Supabase ou la CLI :

1.  `supabase/migrations/202502191200_document_verification.sql`
    *   Ajoute `verification_status`, `ai_analysis`, `rejection_reason` √† la table `documents`.
2.  `supabase/migrations/202502191300_ticket_maintenance_ai.sql`
    *   Ajoute `ai_summary`, `ai_suggested_action`, `ai_suggested_provider_type` √† la table `tickets`.

## 3. V√©rification des Services

Les services suivants ont √©t√© cr√©√©s et sont auto-initialis√©s :

*   `features/documents/services/document-ai.service.ts`
*   `features/tickets/services/messaging-ai.service.ts`
*   `features/tickets/services/maintenance-ai.service.ts`

Ils sont appel√©s automatiquement par les routes API existantes :
*   `POST /api/documents/upload-batch` -> D√©clenche l'analyse documentaire.
*   `POST /api/tickets` -> D√©clenche l'analyse maintenance.
*   `POST /api/tickets/[id]/ai-draft` -> Route d√©di√©e pour la g√©n√©ration de r√©ponse.

## 4. Activation "R√©elle" (Sortie du mode Simulation)

Pour passer en mode production r√©el avec GPT-4o :

1.  Ouvrir `features/documents/ai/document-analysis.graph.ts`
2.  Ouvrir `features/tickets/ai/message-draft.graph.ts`
3.  Ouvrir `features/tickets/ai/maintenance.graph.ts`

Dans chaque fichier, remplacer le code mock√© par l'appel LLM :

```typescript
// AVANT (Mock)
/*
const model = new ChatOpenAI(...)
const response = await model.invoke(...)
*/
const extractedData = { ...mock... }

// APR√àS (Prod)
const model = new ChatOpenAI({ modelName: "gpt-4o", temperature: 0 });
const response = await model.invoke(...);
const extractedData = JSON.parse(response.content as string);
```

## 5. Monitoring

Surveillez les logs Vercel/Server pour les tags suivants :
*   `[AI Agent]`
*   `[DocumentAiService]`
*   `[MaintenanceAiService]`

En cas d'erreur IA, les services sont con√ßus pour "fail soft" (ne pas bloquer l'action utilisateur, juste ne pas fournir l'enrichissement IA).

